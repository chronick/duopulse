---
iteration_id: 2026-01-22-005
goal: "Add multi-seed evaluation to remove single-seed bias from metrics"
status: success
started_at: 2026-01-22T21:30:00Z
completed_at: 2026-01-22T22:15:00Z
branch: feature/multi-seed-eval-2026-01-22
commit: 17d8ee5
pr: https://github.com/chronick/duopulse/pull/23
estimate_accuracy: 95
---

# Iteration 2026-01-22-005: Multi-Seed Evaluation

## Goal

Add multi-seed support to the evaluation system to remove single-seed bias and provide more reliable metrics.

## Background

Previous iterations discovered that the eval seed (0xDEADBEEF) creates systematic biases that mask the effect of parameter changes. The existing system tested 8 seeds for pattern variation analysis but only used 1 seed for actual metric computation.

## Baseline Metrics

From baseline v1.0.1 (single-seed 0xDEADBEEF):
- Pentagon Score: 66.4%
- syncopated zone syncopation: 0.64
- Conformance: 87.1% (8/8 pass)

## Implementation

### Changes Made

1. **`tools/evals/generate-patterns.js`**
   - Added EVAL_SEEDS constant with 4 diverse seeds
   - Modified generateSweep() to generate patterns for each seed
   - Updated energy zone sweep generation for multi-seed
   - Updated preset generation for multi-seed
   - Version bumped to 1.1.0

2. **`tools/evals/evaluate-expressiveness.js`**
   - Added `computePentagonMetricsFromSteps()` for raw step data
   - Added `computeMultiSeedPentagonMetrics()` for averaged metrics
   - Added stability calculation (average, stddev helpers)
   - Updated zone statistics to use averaged metrics
   - Added stability section to expressiveness.json output
   - Added per-seed pentagon scores to output

### Data Structure Changes

**Before** (sweeps.json):
```json
{
  "shape": [
    { "params": {...}, "masks": {...}, "hits": {...}, "steps": [...] }
  ]
}
```

**After** (sweeps.json):
```json
{
  "shape": [
    {
      "params": {...},
      "seedPatterns": [
        { "seed": 3735928559, "masks": {...}, "hits": {...}, "steps": [...] },
        { "seed": 3405691582, "masks": {...}, "hits": {...}, "steps": [...] },
        ...
      ]
    }
  ]
}
```

## Result Metrics

### Pentagon Stability Analysis

| Metric | Stability | Interpretation |
|--------|-----------|----------------|
| Syncopation | 37% | HIGH variance across seeds - confirms seed bias |
| Density | 88% | Stable |
| Velocity Range | 96% | Very stable |
| Voice Separation | 78% | Moderately stable |
| Regularity | 87% | Stable |
| Overall | 77% | Acceptable overall stability |

### Per-Seed Pentagon Scores

| Seed | Pentagon Score | Delta from Avg |
|------|----------------|----------------|
| 0xDEADBEEF (original) | 47.9% | +18.5% |
| 0xCAFEBABE | 28.1% | -1.3% |
| 0x12345678 | 25.8% | -3.6% |
| 0xABCD1234 | 26.0% | -3.4% |

**Key Finding**: The original seed 0xDEADBEEF was producing scores ~20% higher than other seeds, confirming significant single-seed bias.

### Zone Metric Comparison

| Zone | Syncopation (single-seed) | Syncopation (multi-seed avg) |
|------|---------------------------|------------------------------|
| Stable | 0.00 | 0.00 |
| Syncopated | 0.64 | 0.43 |
| Wild | 0.88 | 0.88 |

**Interpretation**: Syncopated zone syncopation dropped from 0.64 to 0.43 when averaged across seeds. This reveals that the 0.64 score was inflated by the single seed choice.

### Test Results

- All 376 unit tests pass
- 62,980 assertions verified
- No regressions

## Implications

### The Syncopation Challenge

The multi-seed results reveal that syncopated zone syncopation (0.43) is still below target (0.70-1.00). The improvement from iteration 004 (rotation) was partially real and partially seed-artifact:

- **Real gain**: From 0.21 to ~0.43 (genuine +105% improvement)
- **Seed artifact**: 0.43 to 0.64 was specific to seed 0xDEADBEEF

This means future iterations targeting syncopation need to improve the multi-seed average, not just the single-seed value.

### Metric Stability Insights

1. **Syncopation is highly seed-dependent** (37% stable) - makes sense because hit positions vary with seed
2. **Density is stable** (88%) - expected since hit COUNT is parameter-driven
3. **Velocity Range is very stable** (96%) - velocity computation is deterministic
4. **Regularity is stable** (87%) - gap uniformity is robust across position changes

## Lessons Learned

### What We Got Right
- Hypothesis that single-seed evaluation creates bias was correct
- Implementation was straightforward (mostly data structure changes)
- 4 seeds provides meaningful averaging without excessive computation

### What Surprised Us
- The magnitude of seed bias: 20% difference between best and worst seed
- Pentagon Score average dropped significantly (66.4% â†’ ~32%)
- Syncopation is by far the most seed-sensitive metric

### Root Cause Understanding

Seed sensitivity in syncopation makes sense:
1. Syncopation = hits on weak metric positions
2. Gumbel selection with different seeds produces different hit positions
3. Some seeds happen to produce more off-beat positions than others
4. 0xDEADBEEF was lucky in this regard

## Files Changed

1. `tools/evals/generate-patterns.js` - Multi-seed pattern generation
2. `tools/evals/evaluate-expressiveness.js` - Multi-seed metric computation

## Decision

**SUCCESS** - Multi-seed evaluation implemented and reveals significant insights about metric reliability.

## Next Steps

1. Update baseline to v1.1.0 reflecting multi-seed metrics
2. Future syncopation work should target multi-seed average
3. Consider adding stability metrics to pass/fail criteria
4. Document that Pentagon Score baseline changed due to methodology improvement
