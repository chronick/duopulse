# Critique: Iteration 2026-01-19-003 Estimates

**Date**: 2026-01-19
**Status**: Needs Rethinking (Multiple fundamental issues)
**Confidence in this critique**: HIGH (80%)

---

## Summary

The iteration estimates for 2026-01-19-003 show improved domain awareness over iteration 002 (correctly identifying ENERGY vs SHAPE domains), but suffer from **critical blind spots in mechanism understanding, statistical validity, and test coverage** that make the LOW (30%) confidence estimate appropriate but potentially overstated. The proposed change (kAuxKMin: 2→1) may be directionally correct but is built on incomplete data and unvalidated assumptions about how aux patterns affect stable zone regularity.

---

## Critical Issues (Must Address Before Running)

### 1. **FATAL: Sample Size Too Small for Regularity Conclusions**

**Issue**: Only 2 patterns in stable zone test suite
- Baseline shows: `stable: { count: 2, regularity: 0.5580... }`
- N=2 is statistically invalid for any meaningful inference
- Minimum viable N for metric validation: 10-15 patterns minimum

**Why this is critical**:
- A single pattern change could swing regularity by ±25% due to pure randomness
- Confidence intervals at N=2 are essentially meaningless
- Prediction accuracy cannot be properly estimated with such small sample

**Impact**: The iteration could succeed OR fail based entirely on which 2 patterns happen to be in the test set, not because the lever change is effective.

**What to do**:
- **Expand stable zone test suite to ≥10 patterns BEFORE attempting this iteration**
- Document current test set generation logic (how are those 2 patterns selected?)
- Run sensitivity analysis on aux-related levers with expanded test set first

**Evidence**:
- Baseline.json explicitly shows `count: 2` for stable zone
- Statistical power analysis: N=2, expecting ±10% effect, would require effect size >0.5σ to detect reliably
- Compare to syncopated zone (N=28) and wild zone (N=3) - stable zone is most under-tested

---

### 2. **MECHANISM UNVALIDATED: Does kAuxKMin Actually Operate at ENERGY≈0?**

**Issue**: The core assumption is unproven:
> "At low ENERGY (stable zone), aux patterns use k closer to kAuxKMin"

Looking at the code (`AlgorithmWeights.cpp`):
```cpp
params.auxK = kAuxKMin + static_cast<int>(energy * (kAuxKMax - kAuxKMin));
```

This is **linear scaling**: at ENERGY=0, `auxK = kAuxKMin = 2` ✓

**But the real question is**: Does reducing aux K actually increase anchor regularity?

- Aux (CV Out 1) is a **separate voice** from Voice 1 (anchor)
- Regularity metric measures **Voice 1 hits only** (per code: `computeRegularity(v1Hits, length)`)
- Reducing aux K → fewer aux hits, but aux hits don't directly affect Voice 1 hit spacing

**The missing link**: How does aux density affect anchor regularity?
- Directly? (no mechanical reason)
- Indirectly through COMPLEMENT (Voice 2 gap-filling)? (maybe, but weak)
- Via visual feedback loop? (not relevant to pattern generation)

**Impact**: You may be tuning a parameter that has minimal mechanical coupling to the target metric.

**What to do**:
- Trace the causal path: kAuxKMin → anchor hit spacing → regularity
- Check: do ENERGY-domain levers for aux voice even affect Voice 1 spacing?
- Consider alternatives: kAnchorKMin/Max are more direct levers for anchor regularity
- Run isolated test: generate patterns with kAuxKMin=2 vs 1, measure if anchor regularity changes at all

**Evidence**:
- Bootstrap heuristic lists kAnchorKMin as secondary lever for stability (line 162, algorithm_config.h)
- Iteration 002 lesson explicitly warns: "Use levers in correct domain" - kAuxKMin is ENERGY domain but aux channel
- Specification (main.md) doesn't document aux as affecting anchor regularity

---

### 3. **CONFIDENCE MISMATCH: 30% Confidence Contradicts the Rationale**

**Issue**: You state 30% confidence due to "no sensitivity data" but then propose a specific change

Sensitivity matrix (`sensitivity-matrix.json`) **is incomplete**:
- Shows **only SHAPE parameters** (all entries are shapeZone*, shapeCrossfade*)
- Shows **ZERO entries for kAuxKMin, kAnchorKMin, kAnchorKMax**, etc.
- This is the real problem: ENERGY-domain levers aren't in the sensitivity matrix at all

**The math**:
- Previous iteration (002) had -86% accuracy (14% vs 100%)
- You're applying lesson: "Use correct domain lever"
- But new lever has zero empirical data vs old approach which had some (poor) data
- This iteration is actually going MORE data-blind than 002

**Why 30% is understated**:
- Should be closer to **15-20% confidence** given complete lack of aux-to-anchor coupling evidence
- OR should be **higher (50-70%) if you had sensitivity data** showing kAuxKMin→regularity R² > 0.4

**What to do**:
- Generate sensitivity data for kAuxKMin first (`make sensitivity-matrix`)
- Review the resulting R² values
- If R² < 0.2 for regularity, abandon this approach entirely
- If R² > 0.4, revise confidence to 60-70%

**Evidence**:
- Sensitivity matrix generated 2026-01-19T03:35:23Z shows only SHAPE parameters
- Iteration 002 lesson documents confidence downgrade from 4/5 to 2/5
- Bootstrap lever heuristic (algorithm_config.h) lists kAuxKMin support as "2/5 - DOWNGRADED"

---

### 4. **SECONDARY EFFECTS IGNORED: Voice Separation & Density Coupling**

**Issue**: The secondary effects prediction assumes aux density drop doesn't cascade

Current state:
- Stable zone density: 0.59 (target 0.15-0.32, **currently 1.8x above target**)
- Stable zone voiceSeparation: 0.895 (target 0.62-0.88, **within range but on high end**)

Predicted change:
- Reducing aux K by 1 hit (2→1) reduces aux density by ~50%
- Your estimate: -3-5% density
- But actual density is already **above target**, so -3-5% is helpful

**The hidden risk**:
- If aux is currently providing 50% of voice separation (gap-filling hypothesis), then -50% aux hits could:
  - Drop voice separation from 0.895 → 0.85+ (still in range, barely)
  - OR drop to 0.80 if aux gaps are critical (potential regression)

**Current coupling is unknown**: You don't have data on aux contribution to voice separation

**What to do**:
- Run experiment: measure voice separation with kAuxKMin=2 vs 1 at ENERGY=0-0.1
- If voiceSeparation drops >2%, this is a regression risk
- Document minimum acceptable voiceSeparation before making change

**Evidence**:
- Spec (main.md section 7) shows COMPLEMENT mechanism relies on finding gaps, aux could fill secondary gaps
- Baseline shows high voice separation for stable (0.895), suggesting current aux density is beneficial
- Risk assessment section mentions "voice separation might decrease" but no mitigation strategy

---

### 5. **WRONG METRIC?: Regularity Calculation May Not Capture Desired Quality**

**Issue**: Regularity measures **gap uniformity** (coefficient of variation), not "danceability"

Formula (evaluate-expressiveness.js lines 197-225):
```javascript
gaps = [spacing between Voice 1 hits]
cv = stdDev(gaps) / mean(gaps)
regularity = 1.0 - cv
```

**Example patterns**:
- Pattern A: [hit, skip, hit, skip, ...] at 16-step pattern (8 hits) → perfectly uniform → cv=0, regularity=1.0
- Pattern B: [4 hits spread across 32 steps] → same regularity metric as Pattern A if gaps are equal
- Pattern C: [4 hits with 6-hit gap, then 20-hit gap] → cv high, regularity low

**The problem**:
- This metric measures **spacing uniformity**, not actual danceability
- A stable zone pattern with 3-4 hits (current density 0.59) and unequal gaps might be more musical than ultra-uniform
- Reducing aux K doesn't directly affect anchor hit spacing → shouldn't change cv at all

**Your proposed change affects**:
- Aux density (separate channel)
- Potentially Voice 2 through indirect effects
- Voice 1 spacing? (no direct mechanism identified)

**What to do**:
- Verify: run experiment with kAuxKMin=2 vs 1, measure anchor hit gap distribution
- If gap distribution unchanged → regularity metric unchanged → iteration will fail
- If you want to improve regularity, consider levers that directly affect anchor hit spacing (kAnchorKMin is more direct)

**Evidence**:
- Spec doesn't mention aux as affecting anchor hit spacing
- Regularity formula is gap-uniformity based, not "overall groove"
- Stable zone regularity at 0.56 = coefficient of variation of ~0.44, implying somewhat unequal gaps (plausible for sparse patterns)

---

## Significant Concerns (Should Address)

### A. Bootstrap Heuristic Already Downgraded

From algorithm_config.h (lines 107-113):
```cpp
// Confidence: 2/5 - DOWNGRADED after iteration 2026-01-19-002 failure
// WARNING: SHAPE lever - does NOT affect ENERGY zones (stable/syncopated/wild)
// For zone-specific regularity, use kAnchorKMin/Max instead (ENERGY levers)
```

**Your iteration uses kAuxKMin, not kAnchorKMin.**

The bootstrap comment explicitly recommends **kAnchorKMin** as the ENERGY-domain lever for regularity, but you're using **kAuxKMin**.

Why the switch?
- Aux is part of ENERGY domain ✓
- But kAnchorKMin is specifically called out as "secondary" lever for zone-specific regularity
- kAuxKMin is mentioned nowhere in regularity heuristics

**What to do**: Justify why kAuxKMin over kAnchorKMin for this goal, or pivot to kAnchorKMin instead

---

### B. Prediction Accuracy Calibration Failing

Iteration 002 predicted:
- Target: +10% improvement in regularity
- Actual: +0.4% (prediction accuracy = 4%)

You estimate 30% confidence for iteration 003. If iteration 002's underestimate was 25x weaker than predicted, and your new approach is less data-driven, you should expect:
- **Expected actual: 30% × 4% = 1.2% improvement** (if scaling is logarithmic)
- OR just **"wild guess"** territory if error source is systemic

**What to do**: Document what you learned from iteration 002's failure and why this approach should be different

---

### C. Alternative Leverage Points Not Explored

Specification (section 5.4) shows SHAPE affects anchor hit ratio:

```
| Zone | Anchor Budget | Shimmer Budget |
|------|---------------|----------------|
| Stable (0-30%) | 100% of base | 100% of base |
```

**Question**: Why not improve stability by constraining anchor hits within the stable zone instead of reducing aux? More direct path.

Also consider: Could the "2 pattern" test set be unrepresentative? (e.g., one is already very regular, one is inherently syncopated due to SHAPE value)

---

## Minor Observations

1. **Pre-flight checklist partially incomplete**:
   - "Verified lever parameter domain" ✓
   - "Checked similar goal failed" ✓
   - Missing: "Verified sensitivity data exists" (it doesn't)
   - Missing: "Validated mechanism coupling" (untested)

2. **Learning objectives are good**: Questions 1-4 are exactly right. Frame these as "assumptions to test" not "learning outcomes"

3. **Backup plan is reasonable**: kAnchorKMin as backup is sound, consider making it the primary choice

---

## Strengths

1. **Correct domain identification**: You learned the ENERGY vs SHAPE lesson from iteration 002. That's proper error recovery.

2. **Explicit confidence statement**: Honest 30% confidence beats false precision. That shows calibration awareness.

3. **Clear documentation**: Estimate, rationale, and backup plan are well-articulated.

4. **Learning objectives**: You've identified what the iteration would teach you (questions 1-4 are well-formed).

---

## Recommendations

### Immediate (Before Running This Iteration)

1. **Expand stable zone test set from N=2 to N≥10**
   - Current sample size invalidates any statistical conclusion
   - This is blocking issue #1 above

2. **Generate sensitivity data for ENERGY-domain levers**
   - Run `make sensitivity-matrix` with kAuxKMin sweep
   - Check if regularity has R² > 0.2 (if <0.2, abandon this approach)
   - Compare kAuxKMin vs kAnchorKMin effects

3. **Validate mechanism**: Run isolated test
   - Generate stable zone patterns with kAuxKMin=2 vs 1
   - Measure Voice 1 anchor hit gap distribution
   - Confirm if gaps actually change (if not, regularity won't change)

### If Validation Shows Promise

4. **Reframe iteration goal**:
   - Change from "improve regularity" to "test aux K sensitivity on stable zone"
   - Set realistic success criteria: "aux K affects regularity by measurable ±2% OR identifies aux as non-coupled"
   - This converts a likely-failure into a diagnostic iteration

### If Validation Shows No Promise

5. **Pivot to kAnchorKMin instead**
   - More directly coupled to anchor hit spacing
   - Already recommended in bootstrap heuristics
   - Will have similar N=2 problem but correct mechanism

---

## Verdict

- **Status**: **Needs Rethinking**
- **Why**: Sample size (N=2), unvalidated mechanism coupling, missing sensitivity data make this a blind shot

### What Would Change My Assessment

**To "Ready to implement"**:
- Expand test set to N≥10 ✓
- Show sensitivity R² > 0.4 for kAuxKMin→regularity ✓
- Validate mechanism (anchor gaps change with kAuxKMin) ✓
- Confidence upgrade to 50%+ ✓

**To "Needs iteration"**:
- Generate sensitivity data, validate mechanism, confirm N issue
- Reframe as diagnostic rather than improvement iteration

**To "Needs rethinking"** (current):
- All three validation points above are incomplete

---

## Questions for the Designer

If you disagree with this critique, please clarify:

1. How were the 2 stable zone patterns selected? What are their parameter values (energy, shape)?
2. Do you have evidence (code trace or experiment) that kAuxKMin affects Voice 1 hit spacing?
3. Why kAuxKMin over kAnchorKMin, given the bootstrap heuristic recommendation?
4. What should regularity metric actually measure for "stable zone danceability"? (gap uniformity vs something else?)

---

**Generated**: 2026-01-19
**Critique scope**: Iteration estimates for 2026-01-19-003
**Recommendation**: Run validation experiments before committing to this iteration
